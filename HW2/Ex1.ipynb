{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trung Nguyen - 111752939\n",
    "## Assignment #2: Exploratory Data Analysis in IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# df.dtypes\n",
    "# df['bedroomcnt'].tolist()\n",
    "# df.set_index('bathroomcnt')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "df = pd.read_csv('./data/properties_2016.csv', low_memory=False)\n",
    "# Calculate mean value and replace NaN values with mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_filled = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_filled.corr(method='pearson', min_periods=1)\n",
    "corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_min = corr.min(axis=0)\n",
    "corr_min = corr_min.min()\n",
    "\n",
    "most_negative1 = 'parcelid'\n",
    "most_negative2 = 'parcelid'\n",
    "for index1 ,row in corr.iterrows():\n",
    "    for index2, cell in row.iteritems():\n",
    "        if cell == corr_min:\n",
    "            most_negative1 = index1\n",
    "            most_negative2 = index2\n",
    "            break\n",
    "print('The most negative correlation: %s - %s') %(most_negative1, most_negative2)\n",
    "            \n",
    "max_value=-2\n",
    "max_x=None\n",
    "max_y=None\n",
    "for index1, row in corr.iterrows():\n",
    "    for index2, item in row.iteritems():\n",
    "        if index1==index2:\n",
    "            continue\n",
    "        if item>max_value:\n",
    "            max_value=item\n",
    "            max_x=index1\n",
    "            max_y=index2\n",
    "\n",
    "print('The most positive correlation: %s - %s') %(max_x, max_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(18,18))  \n",
    "sns.heatmap(corr, square=True, ax=ax1, linewidths=0.1, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.read_csv('./data/train_2016_v2.csv')\n",
    "y_dropped = y.drop_duplicates('parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dropped = df_filled.drop([\"hashottuborspa\", \"propertycountylandusecode\", \"propertyzoningdesc\", \n",
    "                        \"fireplaceflag\", \"taxdelinquencyflag\", \"assessmentyear\"], axis=1)\n",
    "X = df_dropped[df_dropped['parcelid'].isin(y_dropped.loc[:,'parcelid'])]\n",
    "X_learn = X.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all features \n",
    "X_learn1 = np.reshape(X_learn, (-1, 52))\n",
    "y_learn = y_dropped['logerror']\n",
    "y_learn = np.reshape(y_learn, (-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_learn1, y_learn, test_size=0.2, random_state=1)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: %.9f\" % regr.coef_[0][0])\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.9f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.9f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, pval = f_regression(X_learn, y_learn.ravel(), center=True)\n",
    "print('The most significant feature (smallest p-value): %s' %X.columns.values[pval.argmin()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only one feature\n",
    "X_learn2 = X_learn['longitude']\n",
    "X_learn2 = np.reshape(X_learn2, (-1, 1))\n",
    "\n",
    "y_learn = y_dropped['logerror']\n",
    "y_learn = np.reshape(y_learn, (-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_learn2, y_learn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: %.9f\" % regr.coef_[0][0])\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.9f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.9f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='red')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=2)\n",
    "plt.ylabel('Log error')\n",
    "plt.xlabel('Longitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill 'longitude' NaN values with its meadian instead of 0\n",
    "longitude_median = df['longitude'].median(skipna=True)\n",
    "X_notfilled = df[df['parcelid'].isin(y_dropped.loc[:,'parcelid'])]\n",
    "X_notfilled.fillna(value=longitude_median, inplace=True)\n",
    "X_learn2 = X_notfilled['longitude'].copy()\n",
    "X_learn2 = np.reshape(X_learn2, (-1, 1))\n",
    "\n",
    "y_learn = y_dropped['logerror']\n",
    "y_learn = np.reshape(y_learn, (-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_learn2, y_learn, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print(\"Coefficients: %.9f\" % regr.coef_[0][0])\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.9f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.9f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(X_test, y_test,  color='red')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=2)\n",
    "plt.ylabel('Log error')\n",
    "plt.xlabel('Longitude')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_predict = np.reshape(df_dropped, (-1, 52))\n",
    "X_predict = np.reshape(df_dropped['longitude'], (-1, 1))\n",
    "\n",
    "y_pred = regr.predict(X_predict)\n",
    "df1 = pd.read_csv('./data/sample_submission.csv', low_memory=False)\n",
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.ndarray.flatten(y_pred)\n",
    "df3 = pd.DataFrame({'Log error prediction': y_pred})\n",
    "df2['201610'] = df3['Log error prediction']\n",
    "df2['201611'] = df3['Log error prediction']\n",
    "df2['201612'] = df3['Log error prediction']\n",
    "df2['201710'] = df3['Log error prediction']\n",
    "df2['201711'] = df3['Log error prediction']\n",
    "df2['201712'] = df3['Log error prediction']\n",
    "df2.to_csv('./data/out.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
